{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News Detection Analysis\n",
    "\n",
    "This notebook provides a comprehensive analysis of fake news detection using machine learning techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from fake_news_detector import FakeNewsDetector\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the detector\n",
    "detector = FakeNewsDetector()\n",
    "\n",
    "# Load sample data\n",
    "df = detector.load_data()\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nDataset info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Count plot\n",
    "plt.subplot(1, 2, 1)\n",
    "label_counts = df['label'].value_counts()\n",
    "plt.pie(label_counts.values, labels=['Fake', 'Real'], autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Distribution of News Labels')\n",
    "\n",
    "# Bar plot\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.countplot(data=df, x='label')\n",
    "plt.title('Count of Real vs Fake News')\n",
    "plt.xlabel('Label (0=Fake, 1=Real)')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Real news articles: {sum(df['label'])}\")\n",
    "print(f\"Fake news articles: {len(df) - sum(df['label'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text length analysis\n",
    "df['title_length'] = df['title'].str.len()\n",
    "df['text_length'] = df['text'].str.len()\n",
    "df['content_length'] = df['content'].str.len()\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Title length distribution\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(data=df, x='label', y='title_length')\n",
    "plt.title('Title Length by Label')\n",
    "plt.xlabel('Label (0=Fake, 1=Real)')\n",
    "\n",
    "# Text length distribution\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(data=df, x='label', y='text_length')\n",
    "plt.title('Text Length by Label')\n",
    "plt.xlabel('Label (0=Fake, 1=Real)')\n",
    "\n",
    "# Content length distribution\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(data=df, x='label', y='content_length')\n",
    "plt.title('Content Length by Label')\n",
    "plt.xlabel('Label (0=Fake, 1=Real)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Text Preprocessing and Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features\n",
    "detector.prepare_features()\n",
    "\n",
    "print(f\"Training set shape: {detector.X_train.shape}\")\n",
    "print(f\"Test set shape: {detector.X_test.shape}\")\n",
    "print(f\"Number of features: {detector.X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show examples of processed text\n",
    "print(\"Original vs Processed Text Examples:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Original: {df.iloc[i]['content'][:100]}...\")\n",
    "    print(f\"Processed: {df.iloc[i]['processed_content'][:100]}...\")\n",
    "    print(f\"Label: {'Real' if df.iloc[i]['label'] == 1 else 'Fake'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all models\n",
    "detector.train_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models\n",
    "results = detector.evaluate_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification reports\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Detailed Classification Reports:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for name, model in detector.trained_models.items():\n",
    "    y_pred = model.predict(detector.X_test)\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(classification_report(detector.y_test, y_pred, target_names=['Fake', 'Real']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for Random Forest\n",
    "if 'Random Forest' in detector.trained_models:\n",
    "    rf_model = detector.trained_models['Random Forest']\n",
    "    feature_names = detector.vectorizer.get_feature_names_out()\n",
    "    importances = rf_model.feature_importances_\n",
    "    \n",
    "    # Create feature importance dataframe\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    # Plot top 20 features\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_features = feature_importance_df.head(20)\n",
    "    sns.barplot(data=top_features, y='feature', x='importance')\n",
    "    plt.title('Top 20 Most Important Features (Random Forest)')\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Top 10 Most Important Features:\")\n",
    "    print(feature_importance_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Word Clouds Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate word clouds\n",
    "detector.generate_word_clouds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Interactive Prediction Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test predictions on sample articles\n",
    "test_articles = [\n",
    "    \"Scientists at Harvard University have published groundbreaking research on climate change in the journal Nature.\",\n",
    "    \"SHOCKING: Local grandmother discovers aliens living in her attic for 20 years!\",\n",
    "    \"The stock market experienced significant volatility today following the Federal Reserve's announcement.\",\n",
    "    \"BREAKING: Time travel proven real by high school student using microwave and aluminum foil!\"\n",
    "]\n",
    "\n",
    "print(\"Testing Predictions on Sample Articles:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, article in enumerate(test_articles, 1):\n",
    "    print(f\"\\nTest Article {i}:\")\n",
    "    print(f\"Text: {article}\")\n",
    "    \n",
    "    # Test with different models\n",
    "    for model_name in ['Naive Bayes', 'Random Forest']:\n",
    "        result = detector.predict_news(article, model_name)\n",
    "        print(f\"{model_name}: {result['prediction']} (Confidence: {result['confidence']:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive performance comparison\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "performance_metrics = []\n",
    "\n",
    "for name, model in detector.trained_models.items():\n",
    "    y_pred = model.predict(detector.X_test)\n",
    "    \n",
    "    metrics = {\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(detector.y_test, y_pred),\n",
    "        'Precision': precision_score(detector.y_test, y_pred),\n",
    "        'Recall': recall_score(detector.y_test, y_pred),\n",
    "        'F1-Score': f1_score(detector.y_test, y_pred)\n",
    "    }\n",
    "    performance_metrics.append(metrics)\n",
    "\n",
    "performance_df = pd.DataFrame(performance_metrics)\n",
    "\n",
    "# Display performance table\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(performance_df.round(4))\n",
    "\n",
    "# Plot performance metrics\n",
    "plt.figure(figsize=(12, 8))\n",
    "metrics_to_plot = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "\n",
    "x = np.arange(len(performance_df))\n",
    "width = 0.2\n",
    "\n",
    "for i, metric in enumerate(metrics_to_plot):\n",
    "    plt.bar(x + i*width, performance_df[metric], width, label=metric)\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.xticks(x + width*1.5, performance_df['Model'], rotation=45)\n",
    "plt.legend()\n",
    "plt.ylim(0, 1.1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion and Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings:\n",
    "1. **Model Performance**: Compare which models performed best on the fake news detection task\n",
    "2. **Feature Importance**: Identify the most important words/features for classification\n",
    "3. **Text Patterns**: Analyze differences between real and fake news content\n",
    "\n",
    "### Next Steps for Improvement:\n",
    "1. **Larger Dataset**: Train on larger, more diverse datasets\n",
    "2. **Advanced Features**: Include metadata, source credibility, social media signals\n",
    "3. **Deep Learning**: Experiment with BERT, LSTM, or other neural networks\n",
    "4. **Real-time Updates**: Implement online learning for adapting to new patterns\n",
    "5. **Ensemble Methods**: Combine multiple models for better performance\n",
    "\n",
    "### Production Considerations:\n",
    "1. **Scalability**: Optimize for handling large volumes of articles\n",
    "2. **Interpretability**: Provide explanations for predictions\n",
    "3. **Bias Detection**: Monitor and mitigate potential biases\n",
    "4. **Continuous Monitoring**: Track model performance over time\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
